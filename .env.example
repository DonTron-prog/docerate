# Environment Configuration
# Copy this file to .env and update with your values

# Environment (local or production)
ENVIRONMENT=local

# API Configuration
DEBUG=true
API_PREFIX=/api

# Data directories
DATA_DIR=data

# Embedding Configuration
EMBEDDING_PROVIDER=local  # local or bedrock
EMBEDDING_MODEL=all-MiniLM-L6-v2  # For local
# EMBEDDING_MODEL=amazon.titan-embed-text-v1  # For Bedrock

# LLM Configuration
LLM_PROVIDER=ollama  # ollama or bedrock
LLM_MODEL=llama3.2  # For Ollama
OLLAMA_HOST=http://localhost:11434

# AWS Configuration (for production)
# AWS_REGION=us-east-1
# S3_BUCKET=your-rag-bucket
# BEDROCK_MODEL_ID=anthropic.claude-3-haiku-20240307-v1:0
# BEDROCK_EMBEDDING_MODEL=amazon.titan-embed-text-v1

# Search Configuration
SEARCH_TOP_K=10
SEARCH_ALPHA=0.7
SEARCH_RERANK=true

# Generation Configuration
GENERATION_MAX_TOKENS=2048
GENERATION_TEMPERATURE=0.7

# Cache Configuration
ENABLE_CACHE=true
CACHE_TTL=3600