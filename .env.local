# Local Development Environment Configuration
# For dev/prod parity, this uses AWS Bedrock embeddings locally
# Copy this file to .env and update with your values

# Environment
ENVIRONMENT=local
DEBUG=true
API_PREFIX=/api

# Data directories
DATA_DIR=data
CONTENT_DIR=content/posts
IMAGE_DIR=content/images
IMAGE_BASE_URL=/images

# IMPORTANT: Embedding Configuration
# For dev/prod parity, we use the same Bedrock model as production
EMBEDDING_PROVIDER=bedrock
EMBEDDING_MODEL=amazon.titan-embed-text-v2:0
EMBEDDING_DIMENSION=1024

# Alternative: Use local model for offline development
# EMBEDDING_PROVIDER=local
# EMBEDDING_MODEL=all-MiniLM-L6-v2
# EMBEDDING_DIMENSION=384

# LLM Configuration for local development
LLM_PROVIDER=ollama
LLM_MODEL=llama3.2
OLLAMA_HOST=http://localhost:11434

# Alternative: Use OpenRouter for better quality
# LLM_PROVIDER=openrouter
# OPENROUTER_API_KEY=your-api-key-here
# OPENROUTER_MODEL=meta-llama/llama-3.2-3b-instruct
# OPENROUTER_SITE_URL=https://localhost:3000
# OPENROUTER_APP_NAME=LocalDev

# AWS Configuration (required for Bedrock embeddings)
AWS_REGION=us-east-1
# AWS credentials should be configured via AWS CLI:
# aws configure --profile default

# Bedrock Configuration
BEDROCK_EMBEDDING_MODEL=amazon.titan-embed-text-v2:0
# Note: Bedrock LLM is optional for local dev
# BEDROCK_MODEL_ID=anthropic.claude-3-haiku-20240307-v1:0

# Search Configuration
SEARCH_TOP_K=10
SEARCH_ALPHA=0.7
SEARCH_RERANK=true

# Generation Configuration
GENERATION_MAX_TOKENS=2048
GENERATION_TEMPERATURE=0.7

# Cache Configuration
ENABLE_CACHE=true
CACHE_TTL=3600